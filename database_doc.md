# üìÑ Documenta√ß√£o do Banco de Dados ‚Äì Projeto Datajud (Amostra)

## 1. Nome do Dataset e Fonte

- **Nome:** Amostra de Processos Datajud (66.311 registros)  
- **Fonte Oficial:** API P√∫blica do Datajud ‚Äì CNJ  
- **Origem Interna:** Tabela `datajud_processos` armazenada em PostgreSQL  
- **Tipo da Amostra:** Probabil√≠stica (`TABLESAMPLE SYSTEM`)
- **Arquivo para ML:** `data/raw/datajud_amostra.csv`

A amostra foi criada especificamente para este projeto, garantindo viabilidade computacional e reprodutibilidade do pipeline.

---

## 2. Justificativa da Amostra

A base completa disponibilizada pelo Datajud possui:

- **‚âà 26 milh√µes de registros**
- **‚âà 78 GB de armazenamento**
- Estruturas JSON profundas (ex.: movimentos, complementos, classes)

Isso torna invi√°vel:

- Rodar EDA diretamente  
- Processar JSON para features  
- Treinar modelos no ambiente local  
- Criar pipelines reprodut√≠veis dentro do prazo do trabalho  

Por isso, foi adotada uma **amostra probabil√≠stica estratificada**, garantindo:

- Representatividade por tribunal e grau  
- Variabilidade suficiente para treinar modelos  
- Rapidez de processamento  
- Reprodutibilidade  

A amostra final cont√©m **66 mil processos**, n√∫mero adequado para:

- an√°lises explorat√≥rias,  
- constru√ß√£o de modelos supervisionados,  
- execu√ß√£o completa do pipeline de MLOps,  
- carregamento r√°pido no Streamlit.

---

## 3. Contexto do Neg√≥cio

O CNJ define metas nacionais como:

- **Meta 1:** Julgar mais processos que os distribu√≠dos  
- **Meta 2:** Julgar processos mais antigos  

Modelos anal√≠ticos ajudam a:

- Identificar padr√µes de julgamento  
- Melhorar previsibilidade de fluxo processual  
- Suportar diagn√≥sticos de produtividade  
- Auxiliar indicadores estrat√©gicos  

Neste projeto, buscamos **prever se um processo j√° apresenta movimentos t√≠picos de julgamento**, usando apenas dados estruturados da capa e da movimenta√ß√£o.

---

## 4. Modelo Conceitual do Dataset

O dataset final √© composto por **uma √∫nica tabela anal√≠tica**, derivada da estrutura JSON bruta do Datajud.

### Diagrama Conceitual (Simples)

Processo
‚îú‚îÄ‚îÄ id (PK)
‚îú‚îÄ‚îÄ tribunal
‚îú‚îÄ‚îÄ grau
‚îú‚îÄ‚îÄ classe_nome
‚îú‚îÄ‚îÄ qtd_movimentos
‚îî‚îÄ‚îÄ foi_julgado (target)


### Dicion√°rio de Dados Final

| Coluna | Tipo | Descri√ß√£o | Exemplo |
|--------|-------|-----------|----------|
| **id** | string | Identificador √∫nico do processo | TRT5_G1_0000‚Ä¶ |
| **tribunal** | string | Sigla do tribunal | TRT6 |
| **grau** | string | Grau de jurisdi√ß√£o (G1, G2) | G1 |
| **classe_nome** | string | Classe processual | ‚ÄúA√ß√£o Trabalhista - Rito Ordin√°rio‚Äù |
| **qtd_movimentos** | int | Quantidade total de movimentos do processo | 84 |
| **foi_julgado** | int (0/1) | Indica se h√° movimento compat√≠vel com julgamento | 1 |

Observa√ß√µes:

- **G1** = Primeira inst√¢ncia  
- **G2** = Segunda inst√¢ncia  
- `foi_julgado` √© definido a partir de palavras-chave nos movimentos (ex.: senten√ßa, julgamento, ac√≥rd√£o, tr√¢nsito etc.)  
- As features foram extra√≠das ap√≥s expandir parcialmente a estrutura JSON original da coluna `data`.

---

## 5. Pr√©-Processamento

### Feito no SQL:

- Extra√ß√£o das colunas √∫teis da estrutura JSON.
- Cria√ß√£o das features:
  - tribunal  
  - grau  
  - classe_nome  
  - qtd_movimentos  
- Cria√ß√£o da vari√°vel-alvo com base em movimentos contendo:
  - ‚Äúsenten√ßa‚Äù
  - ‚Äújulgamento‚Äù
  - ‚Äúac√≥rd√£o‚Äù
  - ‚Äúbaixa‚Äù
  - ‚Äúarquivamento‚Äù
  - ‚Äútr√¢nsito em julgado‚Äù
- Ajuste de tipos e limpeza textual.

### Feito no Python:

- Remo√ß√£o de nulos (SimpleImputer)
- Codifica√ß√£o categ√≥rica (OneHotEncoder)
- Padroniza√ß√£o num√©rica (StandardScaler)
- Encapsulamento no `ColumnTransformer`

---

## 6. Problema de Pesquisa

> **Dado um processo da amostra, qual a probabilidade dele j√° ter sido julgado?**

Tipo: **Classifica√ß√£o Bin√°ria**

- 0 = n√£o julgado  
- 1 = julgado  

### Modelos Utilizados

- üîπ Logistic Regression  
- üîπ Random Forest (melhor desempenho)

M√©trica principal: **F1-Score**, para lidar com classes potencialmente desequilibradas.

---

## 7. Pipeline de MLOps

| Arquivo | Fun√ß√£o |
|--------|--------|
| `src/data_ingestion.py` | Carrega o dataset |
| `src/data_processing.py` | Define pr√©-processamento (transformers) |
| `src/modeling.py` | Treina, avalia e salva o modelo |
| `models/best_pipeline.joblib` | Pipeline final serializada |
| `app.py` | Dashboard interativo em Streamlit |

Propriedades:

- Modular  
- Reprodut√≠vel  
- F√°cil manuten√ß√£o  
- Totalmente automatizado  

---

## 8. Exporta√ß√£o da Base Anal√≠tica

A exporta√ß√£o foi realizada ap√≥s sele√ß√£o das colunas finais:

```sql
SELECT
    id,
    tribunal_clean AS tribunal,
    grau,
    classe_nome,
    qtd_movimentos,
    foi_julgado
FROM datajud_amostra;

Exportada via:

DBeaver ‚Üí Export Resultset ‚Üí CSV ‚Üí data/raw/datajud_amostra.csv

Configura√ß√µes:

Delimitador: ,

Quote: "

Encoding: UTF-8

Header habilitado

9. Conclus√£o

A documenta√ß√£o, o dataset e o pipeline garantem:

Reprodutibilidade

Clareza metodol√≥gica

Organiza√ß√£o l√≥gica

Adequa√ß√£o ao problema de pesquisa

Ader√™ncia √†s metas do CNJ

O dataset final est√° pronto para:

an√°lises explorat√≥rias (EDA)

demonstra√ß√£o do modelo

execu√ß√£o no dashboard

uso futuro em pipelines mais robustos

---

## 10. Modelos Anal√≠ticos e Pipeline de Machine Learning

Atendendo ao item 2 da avalia√ß√£o, o projeto foi estruturado em um pipeline de Machine Learning composto por scripts modulares, que automatizam desde a carga dos dados at√© o treinamento, avalia√ß√£o e serializa√ß√£o do modelo final.

### 10.1 Ingest√£o de Dados (`data_ingestion.py`)

Responsabilidades principais:

- Carregar o arquivo `data/raw/datajud_amostra.csv`;
- Organizar as vari√°veis em:
  - **Features (X):** `tribunal`, `grau`, `classe_nome`, `qtd_movimentos`;
  - **Target (y):** `foi_julgado` (0 = n√£o julgado, 1 = julgado).

Essa separa√ß√£o √© utilizada tanto no processo de modelagem quanto, indiretamente, nas predi√ß√µes realizadas via Streamlit.

### 10.2 Pr√©-Processamento e Transforma√ß√£o (`data_processing.py`)

O pr√©-processamento foi encapsulado em um objeto `ColumnTransformer`, integrado ao `Pipeline` do scikit-learn, garantindo consist√™ncia entre as etapas de treino e predi√ß√£o.

Principais etapas:

- **Tratamento de valores ausentes:**
  - Num√©ricas: imputa√ß√£o pela mediana;
  - Categ√≥ricas: imputa√ß√£o pelo valor mais frequente.
- **Codifica√ß√£o de vari√°veis categ√≥ricas:**
  - Uso de `OneHotEncoder(handle_unknown="ignore")` para as colunas:
    - `tribunal`,
    - `grau`,
    - `classe_nome`.
- **Escalonamento de vari√°veis num√©ricas:**
  - Uso de `StandardScaler` para a vari√°vel `qtd_movimentos`.

Todo esse pr√©-processamento √© aplicado automaticamente dentro do `Pipeline` do scikit-learn, o que garante que os mesmos passos sejam utilizados tanto no treinamento quanto nas predi√ß√µes no aplicativo Streamlit.

### 10.3 Modelagem (`modeling.py`)

Na etapa de modelagem foram treinados e comparados modelos de classifica√ß√£o bin√°ria:

- **Regress√£o Log√≠stica**
- **Random Forest Classifier**

Ambos os modelos foram integrados ao mesmo pr√©-processador via `Pipeline`, de forma que cada candidato a modelo √©, na pr√°tica, um pipeline completo: `preprocessor + model`.

### 10.4 Avalia√ß√£o dos Modelos

Para comparar os modelos, foram utilizadas m√©tricas de classifica√ß√£o, com foco em:

- Acur√°cia;
- Precis√£o;
- Recall;
- **F1-Score** (m√©trica principal).

O script `modeling.py` gera o `classification_report` para cada modelo testado e utiliza o **F1-Score** para selecionar o melhor pipeline.

### 10.5 Serializa√ß√£o do Pipeline

Ap√≥s a compara√ß√£o, o melhor modelo √© escolhido e serializado em disco junto com o pr√©-processamento, utilizando a biblioteca `joblib`:

- Arquivo gerado: `models/best_pipeline.joblib`.

Esse arquivo √© posteriormente carregado no aplicativo Streamlit (`app.py`) para gera√ß√£o das predi√ß√µes em tempo real, sem necessidade de re-treinar o modelo.

---

## 11. Dashboard Interativo com Streamlit (`app.py`)

O dashboard desenvolvido em Streamlit √© o ponto central de apresenta√ß√£o do projeto, cobrindo os elementos solicitados no item 3 da avalia√ß√£o. Ele foi organizado em tr√™s p√°ginas principais, acessadas via barra lateral.

### 11.1 P√°gina 1 ‚Äì Introdu√ß√£o e Contextualiza√ß√£o

Elementos presentes:

- **T√≠tulo do projeto:** contextualiza a utiliza√ß√£o do Datajud e o foco em predi√ß√£o de julgamento de processos;
- **Descri√ß√£o geral da solu√ß√£o:** explica√ß√£o do uso de amostra, pipeline de ML e API p√∫blica;
- **Problema de pesquisa:** ‚ÄúDado um processo, qual a probabilidade de ele j√° ter sido julgado?‚Äù;
- **Resumo da metodologia:** amostragem da base original, constru√ß√£o da tabela anal√≠tica, defini√ß√£o do target `foi_julgado` e treinamento de modelos supervisionados.

Essa p√°gina funciona como uma s√≠ntese textual da Avalia√ß√£o 1 e da evolu√ß√£o para o contexto de MLOps.

### 11.2 P√°gina 2 ‚Äì An√°lise Explorat√≥ria de Dados (EDA)

Elementos principais:

- **Gr√°ficos interativos (Plotly):**
  - Distribui√ß√£o de processos por tribunal (`tribunal`);
  - Distribui√ß√£o por grau (`grau`);
  - Distribui√ß√£o do target (`foi_julgado`), permitindo visualizar a propor√ß√£o entre julgados e n√£o julgados.
- **Visualiza√ß√£o agregada:** os gr√°ficos permitem identificar rapidamente a concentra√ß√£o de processos por tribunal, o comportamento por grau de jurisdi√ß√£o (G1, G2) e o equil√≠brio entre as classes da vari√°vel alvo.

A partir desses gr√°ficos, o usu√°rio consegue entender melhor a composi√ß√£o da amostra antes de acessar a parte preditiva do sistema.

### 11.3 P√°gina 3 ‚Äì An√°lises Preditivas e Relat√≥rio

A p√°gina de modelo preditivo concentra a intera√ß√£o direta com o pipeline treinado.

Componentes:

- **Entrada de dados pelo usu√°rio:**
  - `st.selectbox` para selecionar:
    - Tribunal (`tribunal`);
    - Grau (`grau`);
    - Classe processual (`classe_nome`);
  - `st.number_input` para informar a quantidade de movimentos do processo (`qtd_movimentos`).
- **Gera√ß√£o de predi√ß√£o:**
  - Ao clicar no bot√£o ‚ÄúGerar Predi√ß√£o‚Äù, o app:
    - Monta um `DataFrame` com os valores informados;
    - Aplica o pipeline serializado (`best_pipeline.joblib`);
    - Calcula a classe prevista (0 ou 1) e a probabilidade associada.
- **Apresenta√ß√£o do resultado:**
  - Mensagens em destaque (`st.success` ou `st.error`) informando:
    - Se o modelo prev√™ que o processo **foi julgado** ou **n√£o foi julgado**;
    - A probabilidade estimada, em formato percentual.

Essa estrutura atende ao requisito de **previs√£o interativa**, em que o usu√°rio pode testar diferentes combina√ß√µes de valores e obter a resposta do modelo em tempo real.

Embora a compara√ß√£o gr√°fica de m√©tricas entre modelos (ex.: tabela com acur√°cia e F1 de cada algoritmo) ainda seja feita no terminal durante o treinamento, a arquitetura atual j√° suporta, em futuras vers√µes, a inclus√£o de uma p√°gina extra com esses resultados consolidados.

---
